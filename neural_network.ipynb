{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data_resampled.csv')\n",
    "#data.drop(data.columns[[0]], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>level_0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>index</th>\n",
       "      <th>ticker_x</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "      <th>news_amount</th>\n",
       "      <th>...</th>\n",
       "      <th>2ma</th>\n",
       "      <th>30ma_vol</th>\n",
       "      <th>7ma_vol</th>\n",
       "      <th>2ma_vol</th>\n",
       "      <th>NWP</th>\n",
       "      <th>NMP</th>\n",
       "      <th>label_day</th>\n",
       "      <th>label_week</th>\n",
       "      <th>label_month</th>\n",
       "      <th>NDP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>363</td>\n",
       "      <td>363</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-07</td>\n",
       "      <td>INTC</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.659</td>\n",
       "      <td>0.3410</td>\n",
       "      <td>0.4767</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019472</td>\n",
       "      <td>2.694088e+07</td>\n",
       "      <td>2.694088e+07</td>\n",
       "      <td>31585900.0</td>\n",
       "      <td>-0.009501</td>\n",
       "      <td>-0.055403</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.005182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>364</td>\n",
       "      <td>364</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-08</td>\n",
       "      <td>INTC</td>\n",
       "      <td>0.2080</td>\n",
       "      <td>0.792</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.2732</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005236</td>\n",
       "      <td>2.754346e+07</td>\n",
       "      <td>2.754346e+07</td>\n",
       "      <td>33817150.0</td>\n",
       "      <td>-0.008053</td>\n",
       "      <td>-0.048363</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.008727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>369</td>\n",
       "      <td>369</td>\n",
       "      <td>6</td>\n",
       "      <td>2016-01-15</td>\n",
       "      <td>INTC</td>\n",
       "      <td>0.1225</td>\n",
       "      <td>0.796</td>\n",
       "      <td>0.0815</td>\n",
       "      <td>-0.0278</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.050067</td>\n",
       "      <td>3.535852e+07</td>\n",
       "      <td>4.050031e+07</td>\n",
       "      <td>62551050.0</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>-0.004351</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>370</td>\n",
       "      <td>370</td>\n",
       "      <td>7</td>\n",
       "      <td>2016-01-19</td>\n",
       "      <td>INTC</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.725</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.2263</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000671</td>\n",
       "      <td>3.476939e+07</td>\n",
       "      <td>3.924283e+07</td>\n",
       "      <td>52626000.0</td>\n",
       "      <td>-0.000419</td>\n",
       "      <td>-0.004552</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.003523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>372</td>\n",
       "      <td>372</td>\n",
       "      <td>9</td>\n",
       "      <td>2016-01-26</td>\n",
       "      <td>INTC</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005678</td>\n",
       "      <td>3.304633e+07</td>\n",
       "      <td>3.593286e+07</td>\n",
       "      <td>25597950.0</td>\n",
       "      <td>0.006138</td>\n",
       "      <td>-0.002364</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.002171</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  level_0  Unnamed: 0.1       index ticker_x     neg    neu  \\\n",
       "0         363      363             0  2016-01-07     INTC  0.0000  0.659   \n",
       "1         364      364             1  2016-01-08     INTC  0.2080  0.792   \n",
       "2         369      369             6  2016-01-15     INTC  0.1225  0.796   \n",
       "3         370      370             7  2016-01-19     INTC  0.2750  0.725   \n",
       "4         372      372             9  2016-01-26     INTC  0.0000  1.000   \n",
       "\n",
       "      pos  compound  news_amount  ...       2ma      30ma_vol       7ma_vol  \\\n",
       "0  0.3410    0.4767            1  ... -0.019472  2.694088e+07  2.694088e+07   \n",
       "1  0.0000   -0.2732            1  ... -0.005236  2.754346e+07  2.754346e+07   \n",
       "2  0.0815   -0.0278            2  ... -0.050067  3.535852e+07  4.050031e+07   \n",
       "3  0.0000   -0.2263            1  ...  0.000671  3.476939e+07  3.924283e+07   \n",
       "4  0.0000    0.0000            1  ...  0.005678  3.304633e+07  3.593286e+07   \n",
       "\n",
       "      2ma_vol       NWP       NMP  label_day  label_week  label_month  \\\n",
       "0  31585900.0 -0.009501 -0.055403          0           0           -1   \n",
       "1  33817150.0 -0.008053 -0.048363          0           0           -1   \n",
       "2  62551050.0  0.000042 -0.004351          0           0            0   \n",
       "3  52626000.0 -0.000419 -0.004552          0           0            0   \n",
       "4  25597950.0  0.006138 -0.002364          0           0            0   \n",
       "\n",
       "        NDP  \n",
       "0 -0.005182  \n",
       "1  0.008727  \n",
       "2  0.000672  \n",
       "3 -0.003523  \n",
       "4 -0.002171  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    20153\n",
       "-1    14847\n",
       " 0    14542\n",
       "Name: label_week, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.label_week.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>Open</th>\n",
       "      <th>30ma_comp</th>\n",
       "      <th>7ma_comp</th>\n",
       "      <th>2ma_comp</th>\n",
       "      <th>30ma_vol</th>\n",
       "      <th>7ma_vol</th>\n",
       "      <th>2ma_vol</th>\n",
       "      <th>2ma</th>\n",
       "      <th>30ma</th>\n",
       "      <th>7ma</th>\n",
       "      <th>news_amount</th>\n",
       "      <th>Volume</th>\n",
       "      <th>label_day</th>\n",
       "      <th>label_week</th>\n",
       "      <th>label_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.659000</td>\n",
       "      <td>0.341000</td>\n",
       "      <td>32.279999</td>\n",
       "      <td>0.238350</td>\n",
       "      <td>0.238350</td>\n",
       "      <td>0.23835</td>\n",
       "      <td>2.694088e+07</td>\n",
       "      <td>2.694088e+07</td>\n",
       "      <td>31585900.0</td>\n",
       "      <td>-0.019472</td>\n",
       "      <td>-0.042243</td>\n",
       "      <td>-0.042243</td>\n",
       "      <td>1</td>\n",
       "      <td>37680500.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.208000</td>\n",
       "      <td>0.792000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32.090000</td>\n",
       "      <td>0.067833</td>\n",
       "      <td>0.067833</td>\n",
       "      <td>0.10175</td>\n",
       "      <td>2.754346e+07</td>\n",
       "      <td>2.754346e+07</td>\n",
       "      <td>33817150.0</td>\n",
       "      <td>-0.005236</td>\n",
       "      <td>-0.042526</td>\n",
       "      <td>-0.042526</td>\n",
       "      <td>1</td>\n",
       "      <td>29953800.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.122500</td>\n",
       "      <td>0.796000</td>\n",
       "      <td>0.081500</td>\n",
       "      <td>29.730000</td>\n",
       "      <td>0.066178</td>\n",
       "      <td>0.016986</td>\n",
       "      <td>0.30745</td>\n",
       "      <td>3.535852e+07</td>\n",
       "      <td>4.050031e+07</td>\n",
       "      <td>62551050.0</td>\n",
       "      <td>-0.050067</td>\n",
       "      <td>-0.086694</td>\n",
       "      <td>-0.068068</td>\n",
       "      <td>2</td>\n",
       "      <td>76373900.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.275000</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>29.980000</td>\n",
       "      <td>0.030775</td>\n",
       "      <td>0.105986</td>\n",
       "      <td>-0.11315</td>\n",
       "      <td>3.476939e+07</td>\n",
       "      <td>3.924283e+07</td>\n",
       "      <td>52626000.0</td>\n",
       "      <td>0.000671</td>\n",
       "      <td>-0.077487</td>\n",
       "      <td>-0.056855</td>\n",
       "      <td>1</td>\n",
       "      <td>28878100.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>29.610001</td>\n",
       "      <td>0.002093</td>\n",
       "      <td>0.006943</td>\n",
       "      <td>-0.17000</td>\n",
       "      <td>3.304633e+07</td>\n",
       "      <td>3.593286e+07</td>\n",
       "      <td>25597950.0</td>\n",
       "      <td>0.005678</td>\n",
       "      <td>-0.047762</td>\n",
       "      <td>0.006203</td>\n",
       "      <td>1</td>\n",
       "      <td>24754900.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49537</th>\n",
       "      <td>0.083727</td>\n",
       "      <td>0.867364</td>\n",
       "      <td>0.048909</td>\n",
       "      <td>62.860001</td>\n",
       "      <td>0.316820</td>\n",
       "      <td>0.223100</td>\n",
       "      <td>0.07580</td>\n",
       "      <td>2.111066e+07</td>\n",
       "      <td>2.561874e+07</td>\n",
       "      <td>36126900.0</td>\n",
       "      <td>0.004659</td>\n",
       "      <td>0.064582</td>\n",
       "      <td>0.042889</td>\n",
       "      <td>11</td>\n",
       "      <td>42778700.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49538</th>\n",
       "      <td>0.107333</td>\n",
       "      <td>0.813667</td>\n",
       "      <td>0.079000</td>\n",
       "      <td>212.300003</td>\n",
       "      <td>0.080333</td>\n",
       "      <td>0.016143</td>\n",
       "      <td>-0.19155</td>\n",
       "      <td>1.925290e+06</td>\n",
       "      <td>2.638129e+06</td>\n",
       "      <td>3452250.0</td>\n",
       "      <td>-0.012264</td>\n",
       "      <td>0.002466</td>\n",
       "      <td>-0.020864</td>\n",
       "      <td>3</td>\n",
       "      <td>4937000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49539</th>\n",
       "      <td>0.037750</td>\n",
       "      <td>0.754250</td>\n",
       "      <td>0.207750</td>\n",
       "      <td>33.400002</td>\n",
       "      <td>0.119573</td>\n",
       "      <td>0.287757</td>\n",
       "      <td>1.05930</td>\n",
       "      <td>8.932823e+06</td>\n",
       "      <td>9.011571e+06</td>\n",
       "      <td>9255350.0</td>\n",
       "      <td>-0.004050</td>\n",
       "      <td>-0.066237</td>\n",
       "      <td>-0.020445</td>\n",
       "      <td>4</td>\n",
       "      <td>11533000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49540</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>44.877998</td>\n",
       "      <td>-0.090673</td>\n",
       "      <td>-0.057300</td>\n",
       "      <td>0.15910</td>\n",
       "      <td>6.193407e+07</td>\n",
       "      <td>4.543300e+07</td>\n",
       "      <td>29832250.0</td>\n",
       "      <td>-0.008828</td>\n",
       "      <td>0.051449</td>\n",
       "      <td>-0.014795</td>\n",
       "      <td>3</td>\n",
       "      <td>30910500.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49541</th>\n",
       "      <td>0.180000</td>\n",
       "      <td>0.820000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>39.529999</td>\n",
       "      <td>0.022400</td>\n",
       "      <td>-0.120714</td>\n",
       "      <td>-0.14800</td>\n",
       "      <td>2.561499e+07</td>\n",
       "      <td>1.811951e+07</td>\n",
       "      <td>15695000.0</td>\n",
       "      <td>0.001011</td>\n",
       "      <td>-0.029426</td>\n",
       "      <td>0.002996</td>\n",
       "      <td>1</td>\n",
       "      <td>14875600.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49542 rows Ã— 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            neg       neu       pos        Open  30ma_comp  7ma_comp  \\\n",
       "0      0.000000  0.659000  0.341000   32.279999   0.238350  0.238350   \n",
       "1      0.208000  0.792000  0.000000   32.090000   0.067833  0.067833   \n",
       "2      0.122500  0.796000  0.081500   29.730000   0.066178  0.016986   \n",
       "3      0.275000  0.725000  0.000000   29.980000   0.030775  0.105986   \n",
       "4      0.000000  1.000000  0.000000   29.610001   0.002093  0.006943   \n",
       "...         ...       ...       ...         ...        ...       ...   \n",
       "49537  0.083727  0.867364  0.048909   62.860001   0.316820  0.223100   \n",
       "49538  0.107333  0.813667  0.079000  212.300003   0.080333  0.016143   \n",
       "49539  0.037750  0.754250  0.207750   33.400002   0.119573  0.287757   \n",
       "49540  0.000000  1.000000  0.000000   44.877998  -0.090673 -0.057300   \n",
       "49541  0.180000  0.820000  0.000000   39.529999   0.022400 -0.120714   \n",
       "\n",
       "       2ma_comp      30ma_vol       7ma_vol     2ma_vol       2ma      30ma  \\\n",
       "0       0.23835  2.694088e+07  2.694088e+07  31585900.0 -0.019472 -0.042243   \n",
       "1       0.10175  2.754346e+07  2.754346e+07  33817150.0 -0.005236 -0.042526   \n",
       "2       0.30745  3.535852e+07  4.050031e+07  62551050.0 -0.050067 -0.086694   \n",
       "3      -0.11315  3.476939e+07  3.924283e+07  52626000.0  0.000671 -0.077487   \n",
       "4      -0.17000  3.304633e+07  3.593286e+07  25597950.0  0.005678 -0.047762   \n",
       "...         ...           ...           ...         ...       ...       ...   \n",
       "49537   0.07580  2.111066e+07  2.561874e+07  36126900.0  0.004659  0.064582   \n",
       "49538  -0.19155  1.925290e+06  2.638129e+06   3452250.0 -0.012264  0.002466   \n",
       "49539   1.05930  8.932823e+06  9.011571e+06   9255350.0 -0.004050 -0.066237   \n",
       "49540   0.15910  6.193407e+07  4.543300e+07  29832250.0 -0.008828  0.051449   \n",
       "49541  -0.14800  2.561499e+07  1.811951e+07  15695000.0  0.001011 -0.029426   \n",
       "\n",
       "            7ma  news_amount      Volume  label_day  label_week  label_month  \n",
       "0     -0.042243            1  37680500.0          0           0           -1  \n",
       "1     -0.042526            1  29953800.0          0           0           -1  \n",
       "2     -0.068068            2  76373900.0          0           0            0  \n",
       "3     -0.056855            1  28878100.0          0           0            0  \n",
       "4      0.006203            1  24754900.0          0           0            0  \n",
       "...         ...          ...         ...        ...         ...          ...  \n",
       "49537  0.042889           11  42778700.0          1           1            1  \n",
       "49538 -0.020864            3   4937000.0          0           1            0  \n",
       "49539 -0.020445            4  11533000.0          0           1            1  \n",
       "49540 -0.014795            3  30910500.0          0           1            1  \n",
       "49541  0.002996            1  14875600.0         -1          -1           -1  \n",
       "\n",
       "[49542 rows x 18 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[['neg','neu','pos','Open',\n",
    "             '30ma_comp','7ma_comp','2ma_comp',\n",
    "             '30ma_vol','7ma_vol','2ma_vol',\n",
    "             '2ma','30ma','7ma','news_amount', 'Volume','label_day','label_week','label_month']]\n",
    "# data = data[['neg','neu','pos','30ma_comp']]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49542, 18)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "maximum_value_news = data.iloc[:,10].values.max()\n",
    "minimum_value_news = data.iloc[:,10].values.min()\n",
    "\n",
    "maximum_value_vol = data.iloc[:,11].values.max()\n",
    "minimum_value_vol = data.iloc[:,11].values.min()\n",
    "\n",
    "data['news_amount'] = (data.iloc[:,10] - minimum_value_news) / (maximum_value_news - minimum_value_news)\n",
    "data['Volume'] = (data.iloc[:,11] - minimum_value_vol) / (maximum_value_vol - minimum_value_vol)\n",
    "\n",
    "X = data.iloc[:, :15].values\n",
    "y_week = data.iloc[:, 16].values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = data.iloc[:, :15].values\n",
    "#y_week = data.iloc[:, 16].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_week, test_size = 0.2, random_state = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, numpy.ndarray)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train), type(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.060000</td>\n",
       "      <td>0.054687</td>\n",
       "      <td>-0.080129</td>\n",
       "      <td>-1.290000e-02</td>\n",
       "      <td>9.324918e+07</td>\n",
       "      <td>4.990193e+07</td>\n",
       "      <td>51547100.0</td>\n",
       "      <td>0.006836</td>\n",
       "      <td>0.020245</td>\n",
       "      <td>0.021205</td>\n",
       "      <td>0.818196</td>\n",
       "      <td>0.830097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.264333</td>\n",
       "      <td>0.685667</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>1691.199951</td>\n",
       "      <td>0.300037</td>\n",
       "      <td>-0.046500</td>\n",
       "      <td>-8.607500e-01</td>\n",
       "      <td>4.476017e+06</td>\n",
       "      <td>3.944214e+06</td>\n",
       "      <td>3249300.0</td>\n",
       "      <td>-0.001361</td>\n",
       "      <td>0.024894</td>\n",
       "      <td>0.014156</td>\n",
       "      <td>0.805706</td>\n",
       "      <td>0.832649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.046281</td>\n",
       "      <td>0.824719</td>\n",
       "      <td>0.128989</td>\n",
       "      <td>37.567501</td>\n",
       "      <td>1.346773</td>\n",
       "      <td>3.783686</td>\n",
       "      <td>4.955900e+00</td>\n",
       "      <td>1.853692e+08</td>\n",
       "      <td>1.513464e+08</td>\n",
       "      <td>122300200.0</td>\n",
       "      <td>0.010028</td>\n",
       "      <td>-0.047268</td>\n",
       "      <td>0.009650</td>\n",
       "      <td>0.823060</td>\n",
       "      <td>0.793030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.714000</td>\n",
       "      <td>0.286000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>0.090717</td>\n",
       "      <td>0.007643</td>\n",
       "      <td>2.469500e-01</td>\n",
       "      <td>6.896840e+06</td>\n",
       "      <td>7.377229e+06</td>\n",
       "      <td>8317350.0</td>\n",
       "      <td>-0.009257</td>\n",
       "      <td>-0.020057</td>\n",
       "      <td>-0.006706</td>\n",
       "      <td>0.793676</td>\n",
       "      <td>0.807970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.185667</td>\n",
       "      <td>0.704667</td>\n",
       "      <td>0.109667</td>\n",
       "      <td>113.010002</td>\n",
       "      <td>0.088333</td>\n",
       "      <td>-0.113371</td>\n",
       "      <td>-4.397000e-01</td>\n",
       "      <td>1.410319e+07</td>\n",
       "      <td>1.108621e+07</td>\n",
       "      <td>9278750.0</td>\n",
       "      <td>0.000264</td>\n",
       "      <td>0.065739</td>\n",
       "      <td>0.002402</td>\n",
       "      <td>0.808182</td>\n",
       "      <td>0.855074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39628</th>\n",
       "      <td>0.209500</td>\n",
       "      <td>0.790500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>99.900002</td>\n",
       "      <td>0.040503</td>\n",
       "      <td>-0.028043</td>\n",
       "      <td>-2.135000e-01</td>\n",
       "      <td>5.058103e+06</td>\n",
       "      <td>6.650800e+06</td>\n",
       "      <td>7754200.0</td>\n",
       "      <td>-0.007332</td>\n",
       "      <td>-0.065696</td>\n",
       "      <td>-0.042649</td>\n",
       "      <td>0.796608</td>\n",
       "      <td>0.782913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39629</th>\n",
       "      <td>0.141000</td>\n",
       "      <td>0.709667</td>\n",
       "      <td>0.149333</td>\n",
       "      <td>62.770000</td>\n",
       "      <td>0.230760</td>\n",
       "      <td>0.334243</td>\n",
       "      <td>1.156000e-01</td>\n",
       "      <td>6.173957e+06</td>\n",
       "      <td>6.175129e+06</td>\n",
       "      <td>5535250.0</td>\n",
       "      <td>-0.007472</td>\n",
       "      <td>0.058218</td>\n",
       "      <td>0.004595</td>\n",
       "      <td>0.796394</td>\n",
       "      <td>0.850945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39630</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>380.850006</td>\n",
       "      <td>0.032633</td>\n",
       "      <td>-0.153100</td>\n",
       "      <td>-6.645000e-02</td>\n",
       "      <td>3.222383e+06</td>\n",
       "      <td>3.353243e+06</td>\n",
       "      <td>4689150.0</td>\n",
       "      <td>0.005280</td>\n",
       "      <td>0.074514</td>\n",
       "      <td>0.035639</td>\n",
       "      <td>0.815825</td>\n",
       "      <td>0.859892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39631</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>68.250000</td>\n",
       "      <td>0.023200</td>\n",
       "      <td>-0.003686</td>\n",
       "      <td>-1.290000e-02</td>\n",
       "      <td>7.794723e+06</td>\n",
       "      <td>6.788971e+06</td>\n",
       "      <td>6590850.0</td>\n",
       "      <td>0.000295</td>\n",
       "      <td>-0.116111</td>\n",
       "      <td>0.004439</td>\n",
       "      <td>0.808229</td>\n",
       "      <td>0.755234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39632</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42.970001</td>\n",
       "      <td>0.142670</td>\n",
       "      <td>0.191114</td>\n",
       "      <td>1.110223e-16</td>\n",
       "      <td>1.855900e+06</td>\n",
       "      <td>2.322514e+06</td>\n",
       "      <td>2190250.0</td>\n",
       "      <td>0.004071</td>\n",
       "      <td>0.067101</td>\n",
       "      <td>0.025255</td>\n",
       "      <td>0.813983</td>\n",
       "      <td>0.855822</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39633 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2            3         4         5  \\\n",
       "0      0.000000  1.000000  0.000000    10.060000  0.054687 -0.080129   \n",
       "1      0.264333  0.685667  0.050000  1691.199951  0.300037 -0.046500   \n",
       "2      0.046281  0.824719  0.128989    37.567501  1.346773  3.783686   \n",
       "3      0.000000  0.714000  0.286000    70.000000  0.090717  0.007643   \n",
       "4      0.185667  0.704667  0.109667   113.010002  0.088333 -0.113371   \n",
       "...         ...       ...       ...          ...       ...       ...   \n",
       "39628  0.209500  0.790500  0.000000    99.900002  0.040503 -0.028043   \n",
       "39629  0.141000  0.709667  0.149333    62.770000  0.230760  0.334243   \n",
       "39630  0.000000  1.000000  0.000000   380.850006  0.032633 -0.153100   \n",
       "39631  0.000000  1.000000  0.000000    68.250000  0.023200 -0.003686   \n",
       "39632  0.000000  1.000000  0.000000    42.970001  0.142670  0.191114   \n",
       "\n",
       "                  6             7             8            9        10  \\\n",
       "0     -1.290000e-02  9.324918e+07  4.990193e+07   51547100.0  0.006836   \n",
       "1     -8.607500e-01  4.476017e+06  3.944214e+06    3249300.0 -0.001361   \n",
       "2      4.955900e+00  1.853692e+08  1.513464e+08  122300200.0  0.010028   \n",
       "3      2.469500e-01  6.896840e+06  7.377229e+06    8317350.0 -0.009257   \n",
       "4     -4.397000e-01  1.410319e+07  1.108621e+07    9278750.0  0.000264   \n",
       "...             ...           ...           ...          ...       ...   \n",
       "39628 -2.135000e-01  5.058103e+06  6.650800e+06    7754200.0 -0.007332   \n",
       "39629  1.156000e-01  6.173957e+06  6.175129e+06    5535250.0 -0.007472   \n",
       "39630 -6.645000e-02  3.222383e+06  3.353243e+06    4689150.0  0.005280   \n",
       "39631 -1.290000e-02  7.794723e+06  6.788971e+06    6590850.0  0.000295   \n",
       "39632  1.110223e-16  1.855900e+06  2.322514e+06    2190250.0  0.004071   \n",
       "\n",
       "             11        12        13        14  \n",
       "0      0.020245  0.021205  0.818196  0.830097  \n",
       "1      0.024894  0.014156  0.805706  0.832649  \n",
       "2     -0.047268  0.009650  0.823060  0.793030  \n",
       "3     -0.020057 -0.006706  0.793676  0.807970  \n",
       "4      0.065739  0.002402  0.808182  0.855074  \n",
       "...         ...       ...       ...       ...  \n",
       "39628 -0.065696 -0.042649  0.796608  0.782913  \n",
       "39629  0.058218  0.004595  0.796394  0.850945  \n",
       "39630  0.074514  0.035639  0.815825  0.859892  \n",
       "39631 -0.116111  0.004439  0.808229  0.755234  \n",
       "39632  0.067101  0.025255  0.813983  0.855822  \n",
       "\n",
       "[39633 rows x 15 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(pd.get_dummies(y_train))\n",
    "y_test = np.array(pd.get_dummies(y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       ...,\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 39633 samples\n",
      "Epoch 1/3000\n",
      "39633/39633 [==============================] - 1s 33us/sample - loss: 1.1338 - accuracy: 0.3668\n",
      "Epoch 2/3000\n",
      "39633/39633 [==============================] - 1s 14us/sample - loss: 1.1283 - accuracy: 0.3645\n",
      "Epoch 3/3000\n",
      "39633/39633 [==============================] - 1s 13us/sample - loss: 1.1172 - accuracy: 0.3747\n",
      "Epoch 4/3000\n",
      "39633/39633 [==============================] - 1s 13us/sample - loss: 1.1281 - accuracy: 0.3631\n",
      "Epoch 5/3000\n",
      "39633/39633 [==============================] - 1s 14us/sample - loss: 1.1135 - accuracy: 0.3747\n",
      "Epoch 6/3000\n",
      "39633/39633 [==============================] - 1s 14us/sample - loss: 1.1144 - accuracy: 0.3693\n",
      "Epoch 7/3000\n",
      "39633/39633 [==============================] - 1s 14us/sample - loss: 1.1268 - accuracy: 0.3693\n",
      "Epoch 8/3000\n",
      "39633/39633 [==============================] - 1s 14us/sample - loss: 1.1125 - accuracy: 0.3736\n",
      "Epoch 9/3000\n",
      "39633/39633 [==============================] - 1s 14us/sample - loss: 1.1205 - accuracy: 0.3658\n",
      "Epoch 10/3000\n",
      "39633/39633 [==============================] - 1s 14us/sample - loss: 1.1197 - accuracy: 0.3700\n",
      "Epoch 11/3000\n",
      "39633/39633 [==============================] - 1s 14us/sample - loss: 1.1223 - accuracy: 0.3659\n",
      "Epoch 12/3000\n",
      "39633/39633 [==============================] - 1s 14us/sample - loss: 1.1162 - accuracy: 0.3748\n",
      "Epoch 13/3000\n",
      "39633/39633 [==============================] - 1s 14us/sample - loss: 1.1210 - accuracy: 0.3662\n",
      "Epoch 14/3000\n",
      "39633/39633 [==============================] - 1s 15us/sample - loss: 1.1107 - accuracy: 0.3784\n",
      "Epoch 15/3000\n",
      "39633/39633 [==============================] - 1s 15us/sample - loss: 1.1194 - accuracy: 0.3723\n",
      "Epoch 16/3000\n",
      "39633/39633 [==============================] - 1s 16us/sample - loss: 1.1243 - accuracy: 0.3686\n",
      "Epoch 17/3000\n",
      "39633/39633 [==============================] - 1s 14us/sample - loss: 1.1253 - accuracy: 0.3676\n",
      "Epoch 18/3000\n",
      "39633/39633 [==============================] - 1s 15us/sample - loss: 1.1206 - accuracy: 0.3719\n",
      "Epoch 19/3000\n",
      "39633/39633 [==============================] - 1s 16us/sample - loss: 1.1131 - accuracy: 0.3748\n",
      "Epoch 20/3000\n",
      "39633/39633 [==============================] - 1s 15us/sample - loss: 1.1158 - accuracy: 0.3737\n",
      "Epoch 21/3000\n",
      "39633/39633 [==============================] - 1s 16us/sample - loss: 1.1212 - accuracy: 0.3720\n",
      "Epoch 22/3000\n",
      "39633/39633 [==============================] - 1s 14us/sample - loss: 1.1159 - accuracy: 0.3701\n",
      "Epoch 23/3000\n",
      "39633/39633 [==============================] - 1s 14us/sample - loss: 1.1239 - accuracy: 0.3640\n",
      "Epoch 24/3000\n",
      "39633/39633 [==============================] - 1s 14us/sample - loss: 1.1148 - accuracy: 0.3766\n",
      "Epoch 25/3000\n",
      "39633/39633 [==============================] - 1s 14us/sample - loss: 1.1223 - accuracy: 0.3685\n",
      "Epoch 26/3000\n",
      "39633/39633 [==============================] - 1s 15us/sample - loss: 1.1169 - accuracy: 0.3706\n",
      "Epoch 27/3000\n",
      "39633/39633 [==============================] - 1s 15us/sample - loss: 1.1157 - accuracy: 0.3695\n",
      "Epoch 28/3000\n",
      "39633/39633 [==============================] - 1s 16us/sample - loss: 1.1078 - accuracy: 0.3755\n",
      "Epoch 29/3000\n",
      "39633/39633 [==============================] - 1s 15us/sample - loss: 1.1135 - accuracy: 0.3712\n",
      "Epoch 30/3000\n",
      "39633/39633 [==============================] - 1s 15us/sample - loss: 1.1219 - accuracy: 0.3646\n",
      "Epoch 31/3000\n",
      "39633/39633 [==============================] - 1s 14us/sample - loss: 1.1229 - accuracy: 0.3660\n",
      "Epoch 32/3000\n",
      "39633/39633 [==============================] - 1s 15us/sample - loss: 1.1140 - accuracy: 0.3729\n",
      "Epoch 33/3000\n",
      "39633/39633 [==============================] - 1s 15us/sample - loss: 1.1173 - accuracy: 0.3724\n",
      "Epoch 34/3000\n",
      "39633/39633 [==============================] - 1s 16us/sample - loss: 1.1224 - accuracy: 0.3703\n",
      "Epoch 35/3000\n",
      "39633/39633 [==============================] - 1s 15us/sample - loss: 1.1257 - accuracy: 0.3608\n",
      "Epoch 36/3000\n",
      "39633/39633 [==============================] - 1s 15us/sample - loss: 1.1179 - accuracy: 0.3728\n",
      "Epoch 37/3000\n",
      "39633/39633 [==============================] - 1s 14us/sample - loss: 1.1216 - accuracy: 0.3642\n",
      "Epoch 38/3000\n",
      "39633/39633 [==============================] - 1s 15us/sample - loss: 1.1117 - accuracy: 0.3729\n",
      "Epoch 39/3000\n",
      "39633/39633 [==============================] - 1s 14us/sample - loss: 1.1267 - accuracy: 0.3680\n",
      "Epoch 40/3000\n",
      "39633/39633 [==============================] - 1s 16us/sample - loss: 1.1201 - accuracy: 0.3708\n",
      "Epoch 41/3000\n",
      "39633/39633 [==============================] - 1s 15us/sample - loss: 1.1335 - accuracy: 0.3656\n",
      "Epoch 42/3000\n",
      "39633/39633 [==============================] - 1s 16us/sample - loss: 1.1103 - accuracy: 0.3755\n",
      "Epoch 43/3000\n",
      "39633/39633 [==============================] - 1s 16us/sample - loss: 1.1183 - accuracy: 0.3718\n",
      "Epoch 44/3000\n",
      "39633/39633 [==============================] - 1s 14us/sample - loss: 1.1176 - accuracy: 0.3767\n",
      "Epoch 45/3000\n",
      "39633/39633 [==============================] - 1s 16us/sample - loss: 1.1139 - accuracy: 0.3738\n",
      "Epoch 46/3000\n",
      "39633/39633 [==============================] - 1s 16us/sample - loss: 1.1173 - accuracy: 0.3706\n",
      "Epoch 47/3000\n",
      "39633/39633 [==============================] - 1s 14us/sample - loss: 1.1221 - accuracy: 0.3656\n",
      "Epoch 48/3000\n",
      "39633/39633 [==============================] - 1s 14us/sample - loss: 1.1285 - accuracy: 0.3646\n",
      "Epoch 49/3000\n",
      "39633/39633 [==============================] - 1s 14us/sample - loss: 1.1208 - accuracy: 0.3664\n",
      "Epoch 50/3000\n",
      "39633/39633 [==============================] - 1s 14us/sample - loss: 1.1104 - accuracy: 0.3725\n",
      "Epoch 51/3000\n",
      "39633/39633 [==============================] - 1s 16us/sample - loss: 1.1116 - accuracy: 0.3808\n",
      "Epoch 52/3000\n",
      "39633/39633 [==============================] - 1s 14us/sample - loss: 1.1200 - accuracy: 0.3644\n",
      "Epoch 53/3000\n",
      "39633/39633 [==============================] - 1s 16us/sample - loss: 1.1399 - accuracy: 0.3665s - loss: 1.1295 - accuracy: \n",
      "Epoch 54/3000\n",
      "39633/39633 [==============================] - 1s 15us/sample - loss: 1.1162 - accuracy: 0.3707\n",
      "Epoch 55/3000\n",
      "39633/39633 [==============================] - 1s 15us/sample - loss: 1.1236 - accuracy: 0.3684\n",
      "Epoch 56/3000\n",
      "39633/39633 [==============================] - 1s 15us/sample - loss: 1.1284 - accuracy: 0.3650\n",
      "Epoch 57/3000\n",
      "39633/39633 [==============================] - 1s 17us/sample - loss: 1.1170 - accuracy: 0.3724\n",
      "Epoch 58/3000\n",
      "39633/39633 [==============================] - 1s 15us/sample - loss: 1.1180 - accuracy: 0.3680\n",
      "Epoch 59/3000\n",
      "39633/39633 [==============================] - 1s 14us/sample - loss: 1.1187 - accuracy: 0.3739\n",
      "Epoch 60/3000\n",
      "39633/39633 [==============================] - 1s 16us/sample - loss: 1.1319 - accuracy: 0.3680\n",
      "Epoch 61/3000\n",
      "39633/39633 [==============================] - 1s 17us/sample - loss: 1.1160 - accuracy: 0.3722\n",
      "Epoch 62/3000\n",
      "39633/39633 [==============================] - 1s 18us/sample - loss: 1.1188 - accuracy: 0.3716\n",
      "Epoch 63/3000\n",
      "39633/39633 [==============================] - 1s 15us/sample - loss: 1.1183 - accuracy: 0.3704\n",
      "Epoch 64/3000\n",
      "39633/39633 [==============================] - 1s 15us/sample - loss: 1.1205 - accuracy: 0.3680\n",
      "Epoch 65/3000\n",
      "39633/39633 [==============================] - 1s 15us/sample - loss: 1.1250 - accuracy: 0.3631\n",
      "Epoch 66/3000\n",
      "39633/39633 [==============================] - 1s 15us/sample - loss: 1.1182 - accuracy: 0.3701\n",
      "Epoch 67/3000\n",
      "39633/39633 [==============================] - 1s 16us/sample - loss: 1.1172 - accuracy: 0.3669\n",
      "Epoch 68/3000\n",
      "39633/39633 [==============================] - 1s 14us/sample - loss: 1.1143 - accuracy: 0.3776\n",
      "Epoch 69/3000\n",
      "39633/39633 [==============================] - 1s 16us/sample - loss: 1.1152 - accuracy: 0.3743\n",
      "Epoch 70/3000\n",
      "39633/39633 [==============================] - 1s 14us/sample - loss: 1.1231 - accuracy: 0.3653s - loss: 1.1238 - accuracy\n",
      "Epoch 71/3000\n",
      "39633/39633 [==============================] - 1s 15us/sample - loss: 1.1133 - accuracy: 0.3725\n",
      "Epoch 72/3000\n",
      "39633/39633 [==============================] - 1s 15us/sample - loss: 1.1089 - accuracy: 0.3775\n",
      "Epoch 73/3000\n",
      "39633/39633 [==============================] - 1s 15us/sample - loss: 1.1228 - accuracy: 0.3679\n",
      "Epoch 74/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39633/39633 [==============================] - 1s 17us/sample - loss: 1.1268 - accuracy: 0.3687\n",
      "Epoch 75/3000\n",
      "39633/39633 [==============================] - 1s 15us/sample - loss: 1.1251 - accuracy: 0.3637\n",
      "Epoch 76/3000\n",
      "39633/39633 [==============================] - 1s 15us/sample - loss: 1.1204 - accuracy: 0.3663\n",
      "Epoch 77/3000\n",
      "39633/39633 [==============================] - 1s 14us/sample - loss: 1.1176 - accuracy: 0.3688\n",
      "Epoch 78/3000\n",
      "39633/39633 [==============================] - 1s 14us/sample - loss: 1.1309 - accuracy: 0.3641\n",
      "Epoch 79/3000\n",
      "39633/39633 [==============================] - 1s 14us/sample - loss: 1.1207 - accuracy: 0.3693\n",
      "Epoch 80/3000\n",
      "39633/39633 [==============================] - 1s 14us/sample - loss: 1.1174 - accuracy: 0.3722\n",
      "Epoch 81/3000\n",
      "39633/39633 [==============================] - 1s 15us/sample - loss: 1.1150 - accuracy: 0.3711\n",
      "Epoch 82/3000\n",
      "39633/39633 [==============================] - ETA: 0s - loss: 1.1151 - accuracy: 0.37 - 1s 16us/sample - loss: 1.1160 - accuracy: 0.3699\n",
      "Epoch 83/3000\n",
      "39633/39633 [==============================] - 1s 16us/sample - loss: 1.1254 - accuracy: 0.3669\n",
      "Epoch 84/3000\n",
      "39633/39633 [==============================] - 1s 15us/sample - loss: 1.1183 - accuracy: 0.3694\n",
      "Epoch 85/3000\n",
      "39633/39633 [==============================] - 1s 16us/sample - loss: 1.1159 - accuracy: 0.3711\n",
      "Epoch 86/3000\n",
      "39633/39633 [==============================] - 1s 16us/sample - loss: 1.1258 - accuracy: 0.3665s - loss: 1.1276 - accura\n",
      "Epoch 87/3000\n",
      "39633/39633 [==============================] - 1s 15us/sample - loss: 1.1216 - accuracy: 0.3708\n",
      "Epoch 88/3000\n",
      "39633/39633 [==============================] - 1s 15us/sample - loss: 1.1399 - accuracy: 0.3615\n",
      "Epoch 89/3000\n",
      " 8700/39633 [=====>........................] - ETA: 0s - loss: 1.1063 - accuracy: 0.3722"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-63809966a286>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m   \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# training targets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m   \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m   \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m )\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    122\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 86\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    485\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1820\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1821\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1822\u001b[0;31m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1823\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2118\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2119\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2120\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mgraph_function\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2121\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__eq__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fields_safe\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fields_safe\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_fields_safe\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     91\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_fields_safe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;34m\"\"\"Hash & equality-safe version of all the namedtuple fields.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m     return (self._hash_fix(self.input_signature), self.parent_graph,\n\u001b[0m\u001b[1;32m     94\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_functions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolocation_stack\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m             self.in_cross_replica_context)\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_hash_fix\u001b[0;34m(self, elem)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;31m# Descend into tuples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hash_fix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;31m# Descend into tuples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hash_fix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_hash_fix\u001b[0;34m(self, elem)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;31m# Descend into tuples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hash_fix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;31m# Descend into tuples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hash_fix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_hash_fix\u001b[0;34m(self, elem)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;31m# return the dtype & shape. Else, simply return the element\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m       \u001b[0mhash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m       \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/framework/type_spec.py\u001b[0m in \u001b[0;36m__hash__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__hash__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mhash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_cmp_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/framework/type_spec.py\u001b[0m in \u001b[0;36m__get_cmp_key\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    307\u001b[0m     \u001b[0;34m\"\"\"Returns a hashable eq-comparable key for `self`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m     \u001b[0;31m# TODO(b/133606651): Decide whether to cache this value.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__make_cmp_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_serialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__make_cmp_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/framework/type_spec.py\u001b[0m in \u001b[0;36m__make_cmp_key\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    324\u001b[0m       ])\n\u001b[1;32m    325\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__make_cmp_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorShape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndims\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "week_model = Sequential([\n",
    "  Dense(40, activation='sigmoid', input_shape=(15,)),\n",
    "#   Dense(10, activation='relu'),\n",
    "#   Dense(20, activation='relu'),\n",
    "  Dense(3, activation='softmax'),\n",
    "])\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.1)\n",
    "\n",
    "week_model.compile(\n",
    "  optimizer=opt,\n",
    "  loss='categorical_crossentropy',\n",
    "  metrics=['accuracy']\n",
    ")\n",
    "\n",
    "week_model.fit(\n",
    "  X_train, # training data\n",
    "  y_train, # training targets\n",
    "  batch_size=150,\n",
    "  epochs=3000\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "week_model.evaluate(\n",
    "  X_test,\n",
    "  to_categorical(y_test)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
